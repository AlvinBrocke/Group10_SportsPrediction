# -*- coding: utf-8 -*-
"""Group10_SportsPrediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uBZ7Ao4jSQ035C5vBn1kQovlYkxyzXwR
"""

from google.colab import drive
drive.mount('/content/drive')

"""# **1.  DATA PREPARATION**

---

Includes:
* Loading the dataset
* Handling missing, duplicate and unnecessary data
* Imputing numeric and non-numeric values
* Encoding non-numeric data (Label Encoder)

"""

import numpy as np
import pandas as pd
from numpy import array
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

"""Loading the dataset"""

# Importing the data sets for players 21 and 22
players_21_data = pd.read_csv('/content/drive/MyDrive/MidSem Project/players_21.csv', low_memory=False)
players_22_data = pd.read_csv('/content/drive/MyDrive/MidSem Project/players_22.csv', low_memory=False)

# Creating Data Frames using the loaded data sets
fifa_21 = pd.DataFrame(players_21_data.copy())
fifa_21.head()

"""Dropping Unnecessary Data"""

# Dropping all the duplicate data in the players_21 dataset
fifa_21 = fifa_21.drop_duplicates()

# Drop columns with 30% or more missing values
threshold = 0.3
fifa_21 = fifa_21.dropna(axis=1, thresh=int(threshold * len(fifa_21)))

# Drop columns containing "url"
fifa_21 = fifa_21.drop(columns=[col for col in fifa_21.columns if 'url' in col.lower()])

"""Separating the numerical and non-numerical values"""

# Numeric Values
numeric_fifa_21 = fifa_21.select_dtypes(include=['number'])
numeric_fifa_21 = pd.DataFrame(numeric_fifa_21)

numeric_fifa_21

# Non-numeric values
categorical_fifa_21 = fifa_21.select_dtypes(include=['object', 'category'])

categorical_fifa_21

"""Imputing Numerical & Non-numerical Values"""

# Imputation for Numeric Values
imp_numeric_fifa_21 = numeric_fifa_21.fillna(numeric_fifa_21.median())

imp_numeric_fifa_21.info()

# Imputation for Categorical Values
imp = SimpleImputer(strategy='most_frequent')
imp_categorical_fifa_21 = imp.fit_transform(categorical_fifa_21)
imp_categorical_fifa_21 = pd.DataFrame(imp_categorical_fifa_21)

"""Integer Encoding Categorical Values"""

imp_categorical_fifa_21

label_encoder = LabelEncoder()
# Create a new DataFrame to store the encoded values
encoded_df = pd.DataFrame()

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Loop through each column in the DataFrame
for column in imp_categorical_fifa_21.columns:
    # Encode the current column and add it to the new DataFrame
    encoded_df[column] = label_encoder.fit_transform(imp_categorical_fifa_21[column])

# encoded_df contains the integer encoded values of imp_categorical_fifa_21
encoded_df.info()

encoded_df.columns = categorical_fifa_21.columns

encoded_df

new_fifa_21 = pd.concat([imp_numeric_fifa_21, encoded_df], axis=1)

new_fifa_21

new_fifa_21.info(verbose=True)

"""# **2. FEATURE ENGINEERING**

---

Includes:
- Selecting eatures with high correlation
- Use correlation analysis
"""

# Correlation Analysis Model
overall_corr = new_fifa_21.corr()['overall']

# Display table with
overall_corr

# Correlation threshold (0.5)
high_corr_values = overall_corr[(overall_corr > 0.5) | (overall_corr < -0.5)]

high_corr_values

# Dropping the columns with low correlation to Overall
filtered_fifa_21 = new_fifa_21.loc[:, high_corr_values.index]

filtered_fifa_21.info()

#Scaling the data
sc = StandardScaler()
scaled_fifa_21 = sc.fit_transform(filtered_fifa_21)
fifa_21 = pd.DataFrame(scaled_fifa_21, columns=filtered_fifa_21.columns)
fifa_21

fifa_21.info()

"""# **3. TRAINING MODEL**

---

Includes:
- Create and train models
- Train 5 RegressorModels (RandomForest, XGBoost, Gradient Boost, Decision Tree Regressor, Support Vector Machine)
- Predict values for each Regressor Model
"""

import xgboost as xgb
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

X = filtered_fifa_21.drop(columns=['overall'])
y = filtered_fifa_21['overall']

X

Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=42)

"""***Decision Tree Regressor***"""

dt = DecisionTreeRegressor(random_state=48)
dt.fit(Xtrain, ytrain)
dt_y_pred = dt.predict(Xtest)
dt_mae = mean_absolute_error(ytest, dt_y_pred)
print("Mean Absolute Error:", dt_mae)

"""***RandomForest Regressor***"""

rf = RandomForestRegressor(n_estimators=300, max_depth = 40, random_state=42, n_jobs= -1)
rf.fit(Xtrain, ytrain)
rf_y_pred=rf.predict(Xtest)
rf_mae = mean_absolute_error(ytest, rf_y_pred)
print("Mean Absolute Error:", rf_mae)

"""**XGBoost Regressor**"""

xgb_reg = xgb.XGBRegressor(
    objective ='reg:squarederror',
    colsample_bytree = 0.3,
    learning_rate = 0.1,
    max_depth = 5, alpha = 10,
    n_estimators = 100,
    random_state=42)
xgb_reg.fit(Xtrain, ytrain)
xgb_y_pred = xgb_reg.predict(Xtest)
xgb_mae = mean_absolute_error(ytest, xgb_y_pred)
print("Mean Absolute Error:", xgb_mae)

"""***Gradient Boost***"""

gb = GradientBoostingRegressor(
    n_estimators=100,
    learning_rate=0.1,
    random_state = 42,
    max_depth = 3)
gb.fit(Xtrain, ytrain)
gb_y_pred = gb.predict(Xtest)
gb_mae = mean_absolute_error(ytest, gb_y_pred)
print("Mean Absolute Error:", gb_mae)

"""***Support Vector Machine (SVM)***"""

svr = SVR(kernel='rbf')
svr.fit(Xtrain, ytrain)
svr_y_pred = svr.predict(Xtest)
svr_mae = mean_absolute_error(ytest, svr_y_pred)
print("Mean Absolute Error:", svr_mae)

"""# **4. EVALUATION**
Includes:
- Using Mean Absolute
- Fine Tuning the model
- Repeated training and testing

Training with GridSearch
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold,GridSearchCV

"""CROSS VALIDATION FOR BEST MODEL"""

rf_classifier = RandomForestClassifier()

# Define the hyperparameters and their possible values for tuning
param_grid = {
    'n_estimators': [50, 100, 150],  # Number of trees in the forest
    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree
    'min_samples_split': [2, 5, 10]   # Minimum number of samples required to split an internal node
}

# Perform Grid Search Cross-Validation
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)
grid_search.fit(X, y)

# Print the best parameters and corresponding accuracy score
print("Best Parameters: ", grid_search.best_params_)
print("Best Accuracy Score: {:.2f}".format(grid_search.best_score_))

# Optionally, you can also perform cross-validation with the best parameters found
best_rf_classifier = grid_search.best_estimator_
cv_scores = cross_val_score(best_rf_classifier, X, y, cv=5)
print("Cross-Validation Scores: ", cv_scores)
print("Mean CV Accuracy: {:.2f}".format(cv_scores.mean()))

"""TESTING WITH FIFA 22 DATASET"""

# Creating Data Frames using the loaded data sets
fifa_22 = pd.DataFrame(players_22_data.copy())
fifa_22.head()

"""**WEBSITE CREATION**
* Crete a webpage
* Allow the user to input data
* Use a function to scan the user's input
* Pass the data to the model, it will return
* Click button predict
* Model is a Server Model use .pk or .hd5
* Print the rating and the confidence of the model
"""

# Dropping all the duplicate data in the players_21 dataset
fifa_22 = fifa_22.drop_duplicates()

# Numeric Values
numeric_fifa_22 = fifa_22.select_dtypes(include=['number'])
numeric_fifa_22 = pd.DataFrame(numeric_fifa_22)

# Non-numeric values
categorical_fifa_22 = fifa_22.select_dtypes(include=['object', 'category'])

# Imputation for Numeric Values
imp_numeric_fifa_22 = numeric_fifa_22.fillna(numeric_fifa_22.median())

# Imputation for Categorical Values
imp_categorical_fifa_22 = imp.fit_transform(categorical_fifa_22)
imp_categorical_fifa_22 = pd.DataFrame(imp_categorical_fifa_22)

encoded_22_df = pd.DataFrame()

# Encoding the categorical values
for column in imp_categorical_fifa_22.columns:
    # Encode the current column and add it to the new DataFrame
    encoded_22_df[column] = label_encoder.fit_transform(imp_categorical_fifa_22[column])

# encoded_df contains the integer encoded values of imp_categorical_fifa_21


encoded_22_df.columns = categorical_fifa_22.columns

new_fifa_22 = pd.concat([imp_numeric_fifa_22, encoded_22_df], axis=1)

#Scaling the data
sc = StandardScaler()
scaled_fifa_22 = sc.fit_transform(new_fifa_22)
fifa_22 = pd.DataFrame(scaled_fifa_22, columns=new_fifa_22.columns)

X = new_fifa_22.drop(columns=['overall'])
y = new_fifa_22['overall']

Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=42)

"""Best Parameters:
* max_depth =  30
* min_samples_split = 5
* n_estimators = 150
"""

rf_clf = RandomForestClassifier(n_estimators= 150, max_depth = 30, min_samples_split= 5, random_state=42)
rf_clf.fit(X, y)
y_pred = rf_clf.predict(Xtest)
mae = mean_absolute_error(ytest, y_pred)
print("MAE:", mae)

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(ytest, y_pred)
print("Accuracy:", accuracy)

import pickle
with open('model.pkl', 'wb') as model_file:
    pickle.dump(rf_clf, model_file)